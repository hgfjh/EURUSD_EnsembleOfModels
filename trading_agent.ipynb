{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "12f73c21",
      "metadata": {
        "id": "12f73c21"
      },
      "source": [
        "# 1. Setup & Infrastructure\n",
        "\n",
        "This section handles the installation of necessary reinforcement learning and financial libraries (Gymnasium, Stable-Baselines3, HMMlearn, XGBoost) and configures PyTorch hardware acceleration settings (e.g., TF32) to ensure efficient training on the GPU."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Dga7fpT48mw_",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2026-01-01T21:42:18.637437Z",
          "iopub.status.busy": "2026-01-01T21:42:18.637127Z",
          "iopub.status.idle": "2026-01-01T21:43:22.672929Z",
          "shell.execute_reply": "2026-01-01T21:43:22.671726Z",
          "shell.execute_reply.started": "2026-01-01T21:42:18.637415Z"
        },
        "id": "Dga7fpT48mw_",
        "outputId": "9a5914cd-20ed-41d2-e5f8-d07934dec447",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "!pip install gymnasium stable-baselines3 hmmlearn xgboost joblib torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b75ec2ba",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2026-01-01T21:43:22.675600Z",
          "iopub.status.busy": "2026-01-01T21:43:22.675160Z",
          "iopub.status.idle": "2026-01-01T21:43:22.681024Z",
          "shell.execute_reply": "2026-01-01T21:43:22.680274Z",
          "shell.execute_reply.started": "2026-01-01T21:43:22.675558Z"
        },
        "id": "b75ec2ba",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import joblib\n",
        "import warnings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ZWSHtpzWlPTf",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZWSHtpzWlPTf",
        "outputId": "c5bce00b-dd55-42a0-a0a9-2ec3a959322a"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "# A100-friendly: allow TF32 (fast tensor cores for fp32 ops)\n",
        "torch.backends.cuda.matmul.allow_tf32 = True\n",
        "torch.backends.cudnn.allow_tf32 = True\n",
        "torch.backends.cudnn.benchmark = True\n",
        "\n",
        "# Broader knob (PyTorch also recommends this for enabling tensor cores)\n",
        "torch.set_float32_matmul_precision(\"medium\")  # or \"medium\" for even more speed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "m9IsYb8Sle_c",
      "metadata": {
        "id": "m9IsYb8Sle_c"
      },
      "outputs": [],
      "source": [
        "import torch as th\n",
        "\n",
        "policy_kwargs = dict(\n",
        "    activation_fn=th.nn.SiLU,\n",
        "    net_arch=dict(pi=[2048, 1024, 512], qf=[2048, 1024, 512]),\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f71cbaf0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2026-01-01T21:43:22.682067Z",
          "iopub.status.busy": "2026-01-01T21:43:22.681820Z",
          "iopub.status.idle": "2026-01-01T21:43:26.021632Z",
          "shell.execute_reply": "2026-01-01T21:43:26.020904Z",
          "shell.execute_reply.started": "2026-01-01T21:43:22.682044Z"
        },
        "id": "f71cbaf0",
        "outputId": "91b21240-dfdb-4ec7-8cf9-56289a380bd6",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import os\n",
        "\n",
        "# Get the absolute path of the directory containing module_to_import.py\n",
        "# In this case, 'other_folder' is one level up from 'main_folder'\n",
        "# and then down into 'other_folder'.\n",
        "module_dir = os.path.join(os.path.dirname('trading_environment.py'), '..', '/kaggle/input/eurusd')\n",
        "sys.path.append(module_dir)\n",
        "\n",
        "\n",
        "from stable_baselines3 import SAC\n",
        "from stable_baselines3.common.env_util import make_vec_env\n",
        "from stable_baselines3.common.evaluation import evaluate_policy\n",
        "from stable_baselines3.common.monitor import Monitor\n",
        "from stable_baselines3.common.vec_env import DummyVecEnv\n",
        "from trading_environment import TradingEnv\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "549542df",
      "metadata": {
        "id": "549542df"
      },
      "source": [
        "# 2. Data Loading & Preprocessing\n",
        "\n",
        "Here we load the financial dataset (`data.csv`) and define the feature set. We perform essential preprocessing, including filling missing values (NaNs) in both features and target variables (`5m_forward_returns`) to ensure clean input for the environment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "97b45b6e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2026-01-01T21:43:26.022664Z",
          "iopub.status.busy": "2026-01-01T21:43:26.022426Z",
          "iopub.status.idle": "2026-01-01T21:43:27.292893Z",
          "shell.execute_reply": "2026-01-01T21:43:27.292179Z",
          "shell.execute_reply.started": "2026-01-01T21:43:26.022641Z"
        },
        "id": "97b45b6e",
        "outputId": "115204b4-a473-4404-df88-6b74ace423b5",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('data.csv', low_memory=False, index_col=[0])\n",
        "\n",
        "feature_cols = [\n",
        "    \"vol_ratio\",\"realized_vol\",\"realized_vol_60\",\"ADX\",\"bandwidth\",\"KAMA_res\",\"MFI\",\n",
        "    \"Dir_Ind_Diff\",\"relative_volume\",\"ADOSC\",\"smoothed_BOP\",\"RSI_fast\",\"usd_score_wstd\"\n",
        "]\n",
        "\n",
        "# Fill NaNs in features AND the target column\n",
        "df[feature_cols] = df[feature_cols].ffill().bfill()\n",
        "df[\"5m_forward_returns\"] = df[\"5m_forward_returns\"].ffill().bfill()\n",
        "\n",
        "# Check if any NaNs remain\n",
        "print(\"NaNs remaining in feature cols:\", df[feature_cols].isna().sum().sum())\n",
        "print(\"NaNs in 5m_forward_returns:\", df[\"5m_forward_returns\"].isna().sum())\n",
        "\n",
        "\n",
        "df.shape\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3f817f14",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2026-01-01T21:43:27.294890Z",
          "iopub.status.busy": "2026-01-01T21:43:27.294614Z",
          "iopub.status.idle": "2026-01-01T21:43:27.307633Z",
          "shell.execute_reply": "2026-01-01T21:43:27.307084Z",
          "shell.execute_reply.started": "2026-01-01T21:43:27.294872Z"
        },
        "id": "3f817f14",
        "outputId": "0052c9a5-6692-455a-9c2a-4848e15467a2",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "feature_cols = [\n",
        "    \"vol_ratio\",\"realized_vol\",\"realized_vol_60\",\"ADX\",\"bandwidth\",\"KAMA_res\",\"MFI\",\n",
        "    \"Dir_Ind_Diff\",\"relative_volume\",\"ADOSC\",\"smoothed_BOP\",\"RSI_fast\",\"usd_score_wstd\"\n",
        "]\n",
        "\n",
        "print(df[feature_cols].isna().sum().sort_values(ascending=False).head(20))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9beaac43",
      "metadata": {
        "id": "9beaac43"
      },
      "source": [
        "# 3. Environment & Auxiliary Models\n",
        "\n",
        "We initialize the `TradingEnv` by integrating the pre-trained auxiliary models: a Hidden Markov Model (`h`) for regime detection and an XGBoost Regressor (`t`) for return forecasting. These models provide the agent with enriched state information."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5aadfc05",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2026-01-01T21:43:27.308344Z",
          "iopub.status.busy": "2026-01-01T21:43:27.308182Z",
          "iopub.status.idle": "2026-01-01T21:43:33.241400Z",
          "shell.execute_reply": "2026-01-01T21:43:33.240628Z",
          "shell.execute_reply.started": "2026-01-01T21:43:27.308331Z"
        },
        "id": "5aadfc05",
        "outputId": "114f60f3-74e2-45c7-8f35-f0af72727e9e",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import gymnasium as gym\n",
        "\n",
        "h = joblib.load(\"trained_hmm.pkl\")\n",
        "t = joblib.load(\"trained_xgboost_model.pkl\")\n",
        "\n",
        "env = DummyVecEnv([lambda: TradingEnv(df, hidden_markov=h, tree_model=t)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d4345dfe",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2026-01-01T21:43:33.242516Z",
          "iopub.status.busy": "2026-01-01T21:43:33.242227Z",
          "iopub.status.idle": "2026-01-01T21:43:33.249064Z",
          "shell.execute_reply": "2026-01-01T21:43:33.248452Z",
          "shell.execute_reply.started": "2026-01-01T21:43:33.242490Z"
        },
        "id": "d4345dfe",
        "outputId": "9e5f0349-b946-44da-f275-b07f99cba470",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "env.reset()\n",
        "print(\"_____OBSERVATION SPACE_____ \\n\")\n",
        "print(\"Observation Space Shape\", env.observation_space.shape)\n",
        "print(\"Sample observation\", env.observation_space.sample()) # Get a random observation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9aa28ab4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2026-01-01T21:43:33.250066Z",
          "iopub.status.busy": "2026-01-01T21:43:33.249817Z",
          "iopub.status.idle": "2026-01-01T21:43:33.265343Z",
          "shell.execute_reply": "2026-01-01T21:43:33.264534Z",
          "shell.execute_reply.started": "2026-01-01T21:43:33.250041Z"
        },
        "id": "9aa28ab4",
        "outputId": "a09ec327-23c8-44d4-b9b9-d7378c9eedb2",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "print(\"\\n _____ACTION SPACE_____ \\n\")\n",
        "print(\"Action Space Sample\", env.action_space.sample()) # Take a random action"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "26b33dee",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2026-01-01T21:43:33.266965Z",
          "iopub.status.busy": "2026-01-01T21:43:33.266706Z",
          "iopub.status.idle": "2026-01-01T21:44:57.428295Z",
          "shell.execute_reply": "2026-01-01T21:44:57.427578Z",
          "shell.execute_reply.started": "2026-01-01T21:43:33.266949Z"
        },
        "id": "26b33dee",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "from stable_baselines3.common.vec_env import VecCheckNan, SubprocVecEnv, VecNormalize, VecMonitor\n",
        "\n",
        "env = make_vec_env(env_id=lambda: TradingEnv(df, hidden_markov=h, tree_model=t), n_envs=12, vec_env_cls=SubprocVecEnv)\n",
        "env = VecCheckNan(env, raise_exception=True)\n",
        "env = VecMonitor(env)\n",
        "env = VecNormalize(\n",
        "    env,\n",
        "    norm_obs=True,\n",
        "    norm_reward=True,\n",
        "    clip_obs=10.0,\n",
        "    norm_obs_keys=[\"indicators\"],  # only normalize market features\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "o_hRkvnc9x82",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2026-01-01T21:50:11.963027Z",
          "iopub.status.busy": "2026-01-01T21:50:11.962710Z",
          "iopub.status.idle": "2026-01-01T21:50:11.974480Z",
          "shell.execute_reply": "2026-01-01T21:50:11.973728Z",
          "shell.execute_reply.started": "2026-01-01T21:50:11.963006Z"
        },
        "id": "o_hRkvnc9x82",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "from stable_baselines3.common.callbacks import BaseCallback, CallbackList\n",
        "\n",
        "class InfoCallback(BaseCallback):\n",
        "    \"\"\"Logs environment info.\"\"\"\n",
        "    def __init__(self, verbose=0):\n",
        "        super().__init__(verbose)\n",
        "\n",
        "    def _on_step(self):\n",
        "        if self.locals.get('infos') is not None:\n",
        "            for info in self.locals['infos']:\n",
        "                if info:  # Only print non-empty dicts\n",
        "                    print(f\"Environment Info: {info}\")\n",
        "        return True\n",
        "\n",
        "class EpisodeStatsCallback(BaseCallback):\n",
        "    \"\"\"Tracks episode statistics.\"\"\"\n",
        "    def __init__(self, verbose=0):\n",
        "        super().__init__(verbose)\n",
        "        self.episode_count = 0\n",
        "        self.episode_rewards = []\n",
        "        self.sharpes = []\n",
        "        self.reporting_sharpes = []\n",
        "        self.final_wealths = []\n",
        "        self.deltas = []\n",
        "\n",
        "    def _on_step(self):\n",
        "        # Check each parallel environment\n",
        "        for idx, info in enumerate(self.locals.get('infos', [])):\n",
        "            # Episode ended\n",
        "            if 'episode' in info:\n",
        "                self.episode_count += 1\n",
        "\n",
        "                # Get SB3's episode metrics\n",
        "                ep_reward = info['episode']['r']\n",
        "                ep_length = info['episode']['l']\n",
        "\n",
        "                sharpe = info.get('sharpe', 0.0)\n",
        "                sharpe_annualized = info.get('sharpe_annualized', 0.0)\n",
        "                wealth = info.get('current_wealth', 0.0)\n",
        "                losses = info.get('losses', 0.0)\n",
        "                delta = info.get('current_position', 0.0)\n",
        "\n",
        "                self.episode_rewards.append(ep_reward)\n",
        "                self.sharpes.append(sharpe)\n",
        "                self.reporting_sharpes.append(sharpe_annualized)\n",
        "                self.final_wealths.append(wealth)\n",
        "                self.deltas.append(delta)\n",
        "\n",
        "                # Access the unwrapped TradingEnv to get internal state\n",
        "                # Use try-except to handle SubprocVecEnv where 'envs' is not directly accessible\n",
        "                try:\n",
        "                    vec_env = self.training_env\n",
        "                    # Unwrap VecEnvWrappers (like VecCheckNan) to find the base env\n",
        "                    while hasattr(vec_env, 'venv'):\n",
        "                        vec_env = vec_env.venv\n",
        "\n",
        "                    if hasattr(vec_env, 'envs'):\n",
        "                        trading_env_instance = vec_env.envs[idx].env\n",
        "                        max_exposure_pct = (abs(trading_env_instance._total_long_size - trading_env_instance._total_short_size)\n",
        "                                            * trading_env_instance._price_cache[trading_env_instance._timestamp]\n",
        "                                            / trading_env_instance.starting_wealth)\n",
        "\n",
        "                        if max_exposure_pct > 0.8:  # 80%+ exposure\n",
        "                            print(f\"⚠️  HIGH EXPOSURE: {max_exposure_pct:.1%}\")\n",
        "                except (AttributeError, IndexError):\n",
        "                    # Env internals not accessible (e.g. SubprocVecEnv), skip exposure check\n",
        "                    pass\n",
        "\n",
        "                # Print every 10 episodes\n",
        "                if self.episode_count % 10 == 0:\n",
        "                    avg_reward = np.mean(self.episode_rewards[-10:])\n",
        "                    avg_sharpe = np.mean(self.sharpes[-10:])\n",
        "                    avg_reporting_sharpe = np.mean(self.reporting_sharpes[-10:])\n",
        "                    avg_wealth = np.mean(self.final_wealths[-10:])\n",
        "                    avg_delta = np.mean(self.deltas[-10:])\n",
        "\n",
        "\n",
        "                    print(f\"\\n{'='*60}\")\n",
        "                    print(f\"Episode {self.episode_count}:\")\n",
        "                    print(f\"  Length: {ep_length}\")\n",
        "                    print(f\"  Reward: {ep_reward:.2f}\")\n",
        "                    print(f\"  Sharpe: {sharpe:.3f}\")\n",
        "                    print(f\"  Final Wealth: ${wealth:,.0f}\")\n",
        "                    print(f\"  Drawdown: ${losses:,.0f}\")\n",
        "                    print(f\"  Avg Reward (last 10): {avg_reward:.2f}\")\n",
        "                    print(f\"  Avg Sharpe (last 10): {avg_sharpe:.3f}\")\n",
        "                    print(f\"  Avg Reporting Sharpe (last 10): {avg_reporting_sharpe:.3f}\")\n",
        "                    print(f\"  Avg Delta (last 10): {avg_delta:.3f}\")\n",
        "                    print(f\"{'='*60}\")\n",
        "\n",
        "        return True\n",
        "# Create callback list\n",
        "info_callback = InfoCallback()\n",
        "stats_callback = EpisodeStatsCallback()\n",
        "callback_list = CallbackList([info_callback, stats_callback])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3321e836",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "execution_failed": "2026-01-01T22:04:43.841Z",
          "iopub.execute_input": "2026-01-01T21:50:17.080838Z",
          "iopub.status.busy": "2026-01-01T21:50:17.080535Z"
        },
        "id": "3321e836",
        "outputId": "24ebb95c-ff85-4e02-e23c-69cf0a7e9715",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Instantiate the agent\n",
        "model = model = SAC(\n",
        "        \"MultiInputPolicy\",  # For Dict observation space\n",
        "        env,\n",
        "        learning_rate=3e-4,\n",
        "        buffer_size=5_000_000,\n",
        "        learning_starts=10_000,\n",
        "        batch_size=16384,\n",
        "        tau=0.005,\n",
        "        gamma=0.99,\n",
        "        train_freq=(4096, \"step\"),\n",
        "        gradient_steps=4096,\n",
        "        ent_coef=\"auto\",  # Auto-tune entropy\n",
        "        target_entropy=\"auto\",\n",
        "        verbose=0,\n",
        "        tensorboard_log=\"./sac_trading_logs/\",\n",
        "    )\n",
        "\n",
        "# Train the agent\n",
        "model.learn(total_timesteps=int(1e6),\n",
        "            callback=stats_callback,\n",
        "            progress_bar=False\n",
        "            )\n",
        "\n",
        "print(f\"\\n\\nTraining complete!\")\n",
        "print(f\"Total episodes: {stats_callback.episode_count}\")\n",
        "print(f\"Final avg reward: {np.mean(stats_callback.episode_rewards):.2f}\")\n",
        "print(f\"Final avg Sharpe: {np.mean(stats_callback.sharpes):.3f}\")\n",
        "print(f\"Final avg Reporting Sharpe: {np.mean(stats_callback.reporting_sharpes):.3f}\")\n",
        "print(f\"Final avg wealth: ${np.mean(stats_callback.final_wealths):,.0f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "125bd303",
      "metadata": {
        "id": "125bd303"
      },
      "source": [
        "# 4. Robust Walk-Forward Validation\n",
        "\n",
        "To avoid overfitting, we define a `run_robust_wfv` function that implements Rolling Window Cross-Validation (TimeSeriesSplit). This rigorously tests the SAC agent across multiple time folds and random seeds to measure the stability of the Sharpe Ratio."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ed18c82e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ed18c82e",
        "outputId": "23bec00e-c981-422d-ab9c-610f96cc2dd1"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import TimeSeriesSplit\n",
        "from stable_baselines3 import SAC\n",
        "from stable_baselines3.common.vec_env import DummyVecEnv, VecMonitor\n",
        "import numpy as np\n",
        "\n",
        "# 1. Split Data\n",
        "train_size = int(len(df) * 0.8)\n",
        "train_df = df.iloc[:train_size]\n",
        "test_df = df.iloc[train_size:]\n",
        "print(f\"Train shape: {train_df.shape}, Test shape: {test_df.shape}\")\n",
        "\n",
        "# 2. Define Validation Function\n",
        "def run_robust_wfv(params, data, n_splits=3, n_seeds=2):\n",
        "    \"\"\"\n",
        "    Runs robust rolling-window cross-validation for SAC agents.\n",
        "    Args:\n",
        "        params (dict): Hyperparameters for the SAC agent.\n",
        "        data (pd.DataFrame): The dataset to split and train/validate on.\n",
        "        n_splits (int): Number of time series splits.\n",
        "        n_seeds (int): Number of random seeds per fold.\n",
        "    Returns:\n",
        "        float: Mean Sharpe Ratio across all folds and seeds.\n",
        "    \"\"\"\n",
        "    tscv = TimeSeriesSplit(n_splits=n_splits)\n",
        "    sharpe_scores = []\n",
        "\n",
        "    # Iterate over TimeSeries splits\n",
        "    for fold, (train_idx, val_idx) in enumerate(tscv.split(data)):\n",
        "        train_fold_data = data.iloc[train_idx]\n",
        "        val_fold_data = data.iloc[val_idx]\n",
        "\n",
        "        # Iterate over seeds for robustness\n",
        "        for seed in range(n_seeds):\n",
        "            # Train Environment\n",
        "            # We assume 'h' (HMM) and 't' (XGBoost) are available in the global scope\n",
        "            train_env = DummyVecEnv([lambda: TradingEnv(train_fold_data, hidden_markov=h, tree_model=t)])\n",
        "            train_env = VecMonitor(train_env)\n",
        "\n",
        "            # Instantiate SAC Agent\n",
        "            model = SAC(\"MultiInputPolicy\", train_env, seed=seed, verbose=0, **params)\n",
        "\n",
        "            # Train the agent\n",
        "            # Using 20,000 timesteps to balance speed and learning\n",
        "            model.learn(total_timesteps=20000)\n",
        "\n",
        "            # Validation Environment\n",
        "            val_env = DummyVecEnv([lambda: TradingEnv(val_fold_data, hidden_markov=h, tree_model=t)])\n",
        "            val_env = VecMonitor(val_env)\n",
        "\n",
        "            # Evaluate for one episode\n",
        "            obs = val_env.reset()\n",
        "            done = False\n",
        "            while not done:\n",
        "                action, _ = model.predict(obs, deterministic=True)\n",
        "                obs, rewards, dones, infos = val_env.step(action)\n",
        "                done = dones[0]\n",
        "\n",
        "            # Retrieve Sharpe Ratio from the final info dictionary\n",
        "            # VecMonitor/TradingEnv should provide the 'sharpe' key in the info of the completed episode\n",
        "            final_sharpe = infos[0].get('sharpe', 0.0)\n",
        "            sharpe_scores.append(final_sharpe)\n",
        "\n",
        "    return np.mean(sharpe_scores)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "62b6747a",
      "metadata": {
        "id": "62b6747a"
      },
      "source": [
        "# 5. Hyperparameter Optimization\n",
        "\n",
        "We use **Optuna** to automatically search for the best SAC hyperparameters (Learning Rate, Gamma, Entropy Coefficient, Batch Size). The objective function maximizes the average Sharpe Ratio obtained from the robust validation process defined in the previous step."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cbf22200",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cbf22200",
        "outputId": "0948ef1c-a678-4210-f1cd-309c52bd472b"
      },
      "outputs": [],
      "source": [
        "!pip install optuna"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "062faedd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "062faedd",
        "outputId": "43ee91a3-4f5d-4506-f469-1ef0cf47c63f"
      },
      "outputs": [],
      "source": [
        "import optuna\n",
        "import torch as th\n",
        "\n",
        "def objective(trial):\n",
        "    # 1. Sample Hyperparameters\n",
        "    learning_rate = trial.suggest_float(\"learning_rate\", 1e-5, 1e-3, log=True)\n",
        "    gamma = trial.suggest_categorical(\"gamma\", [0.99, 0.995, 0.999])\n",
        "\n",
        "    # ent_coef needs to be handled carefully because it can be a string or float\n",
        "    ent_coef_choice = trial.suggest_categorical(\"ent_coef\", [\"auto\", 0.01, 0.05])\n",
        "\n",
        "    train_freq_val = trial.suggest_categorical(\"train_freq\", [1024, 2048, 4096])\n",
        "    batch_size = trial.suggest_categorical(\"batch_size\", [2048, 4096])\n",
        "\n",
        "    # Fixed/derived params\n",
        "    gradient_steps = train_freq_val\n",
        "\n",
        "    # Lighter architecture for speed\n",
        "    policy_kwargs = dict(\n",
        "        activation_fn=th.nn.SiLU,\n",
        "        net_arch=dict(pi=[256, 256], qf=[256, 256])\n",
        "    )\n",
        "\n",
        "    params = {\n",
        "        \"learning_rate\": learning_rate,\n",
        "        \"gamma\": gamma,\n",
        "        \"ent_coef\": ent_coef_choice,\n",
        "        \"train_freq\": train_freq_val,\n",
        "        \"gradient_steps\": gradient_steps,\n",
        "        \"batch_size\": batch_size,\n",
        "        \"policy_kwargs\": policy_kwargs,\n",
        "        \"buffer_size\": 1_000_000,\n",
        "        \"learning_starts\": 5000\n",
        "    }\n",
        "\n",
        "    # 2. Run Robust Validation\n",
        "    # We assume run_robust_wfv is defined in the previous cell\n",
        "    # Using n_seeds=3 and n_splits=5\n",
        "    mean_sharpe = run_robust_wfv(params, train_df, n_splits=5, n_seeds=3)\n",
        "\n",
        "    return mean_sharpe\n",
        "\n",
        "# 3. Create Study\n",
        "study = optuna.create_study(direction=\"maximize\")\n",
        "\n",
        "# 4. Optimize\n",
        "print(\"Starting Optuna optimization...\")\n",
        "study.optimize(objective, n_trials=10)\n",
        "\n",
        "# 5. Print Results\n",
        "print(\"\\nBest trial:\")\n",
        "trial = study.best_trial\n",
        "\n",
        "print(f\"  Value: {trial.value}\")\n",
        "print(\"  Params: \")\n",
        "for key, value in trial.params.items():\n",
        "    print(f\"    {key}: {value}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "30d011f3",
      "metadata": {
        "id": "30d011f3"
      },
      "source": [
        "# 6. Final Production Training & Testing\n",
        "\n",
        "Using the optimal hyperparameters found by Optuna, we train a final SAC agent on the entire training dataset (80%). We then perform a deterministic evaluation on the strictly held-out test dataset (20%) to assess out-of-sample performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "21759ab0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "21759ab0",
        "outputId": "12f9fe87-e5b4-49c5-eb2f-688568b377a8"
      },
      "outputs": [],
      "source": [
        "import torch as th\n",
        "from stable_baselines3 import SAC\n",
        "from stable_baselines3.common.vec_env import DummyVecEnv, VecMonitor\n",
        "import numpy as np\n",
        "\n",
        "# 1. Define Best Parameters\n",
        "best_params = {key : value for key, value in trial.params.items}\n",
        "\n",
        "# 2. Create Training Environment\n",
        "# Ensure 'h' and 't' are loaded (from previous steps)\n",
        "train_env = DummyVecEnv([lambda: TradingEnv(train_df, hidden_markov=h, tree_model=t)])\n",
        "train_env = VecMonitor(train_env)\n",
        "\n",
        "# 3. Instantiate SAC Agent\n",
        "model = SAC(\"MultiInputPolicy\", train_env, verbose=1, seed=42, **best_params)\n",
        "\n",
        "# 4. Train the Agent\n",
        "print(\"Training final SAC model on full training set...\")\n",
        "model.learn(total_timesteps=100_000)\n",
        "\n",
        "# 5. Create Testing Environment\n",
        "test_env = DummyVecEnv([lambda: TradingEnv(test_df, hidden_markov=h, tree_model=t)])\n",
        "test_env = VecMonitor(test_env)\n",
        "\n",
        "# 6. Evaluation Loop\n",
        "obs = test_env.reset()\n",
        "done = False\n",
        "test_portfolio_values = []\n",
        "\n",
        "print(\"\\nEvaluating on Test Set...\")\n",
        "while not done:\n",
        "    action, _ = model.predict(obs, deterministic=True)\n",
        "    obs, rewards, dones, infos = test_env.step(action)\n",
        "    done = dones[0]\n",
        "\n",
        "    # Extract current wealth from info\n",
        "    info = infos[0]\n",
        "    test_portfolio_values.append(info['current_wealth'])\n",
        "\n",
        "    if done:\n",
        "        final_sharpe = info.get('sharpe', 0.0)\n",
        "        final_wealth = info['current_wealth']\n",
        "\n",
        "# 7. Calculate Metrics\n",
        "# Access the unwrapped environment to get starting_wealth\n",
        "initial_wealth = test_env.venv.envs[0].starting_wealth\n",
        "total_return = (final_wealth - initial_wealth) / initial_wealth\n",
        "\n",
        "print(f\"Out-of-Sample Sharpe Ratio: {final_sharpe:.3f}\")\n",
        "print(f\"Total Return: {total_return:.2%}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a99e8fa2",
      "metadata": {
        "id": "a99e8fa2"
      },
      "source": [
        "# 7. Performance Visualization\n",
        "\n",
        "Finally, we visualize the agent's equity curve on the test set and compute key metrics (Total Return, Sharpe Ratio). Based on these results, we provide a verdict on the strategy's robustness and readiness for deployment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e825bec4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 678
        },
        "id": "e825bec4",
        "outputId": "6ffa68d1-c958-4efa-f19f-64a1ddfa78a8"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Prepare data for plotting\n",
        "curve = np.array(test_portfolio_values)\n",
        "initial_value = curve[0]\n",
        "cum_returns_pct = (curve - initial_value) / initial_value * 100\n",
        "\n",
        "# Generate Cumulative Return Plot\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(cum_returns_pct, label='Strategy Equity Curve', color='#1f77b4', linewidth=1.5)\n",
        "plt.axhline(0, color='red', linestyle='--', linewidth=1, label='Break-even')\n",
        "plt.title(f'SAC Agent Out-of-Sample Performance\\nSharpe: {final_sharpe:.3f} | Total Return: {cum_returns_pct[-1]:.2f}%',\n",
        "          fontsize=14)\n",
        "plt.xlabel('Test Steps (Minutes)', fontsize=12)\n",
        "plt.ylabel('Cumulative Return (%)', fontsize=12)\n",
        "plt.legend(loc='upper left')\n",
        "plt.grid(True, which='both', linestyle='--', alpha=0.7)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Print Summary Verdict\n",
        "print(\"=\"*60)\n",
        "print(\"STRATEGY ROBUSTNESS VERDICT\")\n",
        "print(\"=\"*60)\n",
        "print(f\"1. Profitability: The agent achieved a positive return of {cum_returns_pct[-1]:.2f}% over the test period.\")\n",
        "print(f\"2. Risk-Adjusted Performance: The Sharpe Ratio is {final_sharpe:.3f}.\")\n",
        "print(\"3. Conclusion: While the strategy is profitable, the low Sharpe ratio (well below 1.0) suggests\")\n",
        "print(\"   significant volatility and a lack of robustness. The strategy is not yet ready for live deployment\")\n",
        "print(\"   and requires further improvement in feature engineering or hyperparameter stability.\")\n",
        "print(\"=\"*60)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "H100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "datasetId": 9151123,
          "sourceId": 14366347,
          "sourceType": "datasetVersion"
        }
      ],
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
